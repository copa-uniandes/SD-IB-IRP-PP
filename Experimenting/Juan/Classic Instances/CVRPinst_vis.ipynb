{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-11\n"
     ]
    }
   ],
   "source": [
    "######################################     Modules     #######################################\n",
    "import sys\n",
    "from time import process_time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../.')\n",
    "from verbose_module import routing_instances as verb\n",
    "sys.path.append('../../../.')\n",
    "import pIRPgym\n",
    "\n",
    "\n",
    "computer_name = input(\"Running experiment on mac? [Y/n]\")\n",
    "if computer_name == '': \n",
    "    path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/pIRPgym/'\n",
    "    experiments_path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "else: \n",
    "    path = 'C:/Users/jm.betancourt/Documents/Research/pIRPgym/'\n",
    "    experiments_path = 'G:/Mi unidad/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "\n",
    "\n",
    "instances = dict()\n",
    "instances['Li'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Li') if i[-3:]=='vrp']\n",
    "instances['Golden'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Golden') if i[-3:]=='vrp']\n",
    "instances['Uchoa'] = [i for i in os.listdir(path+'pIRPgym/Instances/CVRP Instances/CVRP/Uchoa') if i[-3:]=='vrp']\n",
    "instances['Li'].sort();instances['Golden'].sort()\n",
    "instances['Uchoa'].sort();instances['Uchoa'] = instances['Uchoa'][1:]+[instances['Uchoa'][0]]\n",
    "\n",
    "Policies = ['NN','RCL']\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dCVRP Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29162.5, 14.6, 4.815625, (7170.1186914862155, 22736, 45004)]\n",
      "[31612.8, 14.6, 4.9, (5776.34958775869, 26874, 43366)]\n",
      "[23785.0, 30.4, 4.821875, (1571.8404499185024, 22907, 28456)]\n",
      "[35745.8, 15.5, 4.9359375, (7888.948938863782, 30106, 52560)]\n",
      "[25504.1, 32.5, 4.9234375, (2532.152896252515, 23463, 30378)]\n",
      "[35068.2, 13.9, 5.0328125, (1483.6456315441367, 33276, 37705)]\n",
      "[38339.7, 14.0, 5.44375, (1308.8168741271638, 35603, 40215)]\n",
      "[48856.1, 16.4, 5.2421875, (13027.049584998133, 41142, 75130)]\n",
      "[46392.5, 14.5, 5.534375, (1402.6488691044526, 44546, 48139)]\n",
      "[50347.1, 15.1, 5.7609375, (2399.397776526435, 46674, 53941)]\n",
      "\n",
      "\n",
      "[15713.9, 14.8, 4.5515625, (1508.4965661213816, 14222, 19201)]\n",
      "[17933.0, 13.3, 4.571875, (623.5310738046661, 16777, 19032)]\n",
      "[8475.4, 5.7, 4.5125, (495.9488280054708, 7712, 9510)]\n",
      "[11005.2, 8.7, 4.54375, (932.4252034345704, 10047, 13310)]\n",
      "[13680.3, 12.3, 4.5484375, (1070.8271615905155, 12918, 16619)]\n",
      "[16683.7, 16.0, 4.5484375, (1270.469680866096, 15577, 19445)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "for inst_set in ['Li','Golden']:\n",
    "    if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "    \n",
    "    for instance in instances[inst_set][]:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "        if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "        \n",
    "        for policy in Policies:\n",
    "            end=False\n",
    "            if policy==Policies[-1]: end=True\n",
    "            # print(f'{inst_set}/{policy}/{instance[:-4]}.pkl')\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "            \n",
    "            if policy=='NN':\n",
    "                if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                 performance[3],True,benchmark,end=end)\n",
    "            elif policy=='RCL':\n",
    "                if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                 performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZES = [250,750,1000,2500]\n",
    "ELITE_PROPORTIONS = [0.05,0.15,0.3]\n",
    "MUTATION_RATES = [0.25,0.5,0.75]\n",
    "\n",
    "combinations = [(p,e,m) for p in POPULATION_SIZES for e in ELITE_PROPORTIONS for m in MUTATION_RATES]\n",
    "\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "\n",
    "for instance in [instances['Li'][4]]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "\n",
    "    for (p,e,m) in combinations:\n",
    "        with open(experiments_path+f'{inst_set}/GA/{instance[:-4]}_{p}_{e}_{m}.pkl', 'rb') as file:\n",
    "            # Use pickle.dump to serialize and save the dictionary to the file\n",
    "            performance = pickle.load(file)\n",
    "\n",
    "            # print(f'{p}_{e}_{m} \\t',round((performance[1]-benchmark[0])/benchmark[0],2))\n",
    "            print(f'{p}_{e}_{m} \\t',performance[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVRP Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exo-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'routing_instances' has no attribute 'routing_instances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m inst_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUchoa\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m RCL_averge_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: verb\u001b[38;5;241m.\u001b[39mrouting_instances\u001b[38;5;241m.\u001b[39mprint_head(Policies,inst_set,show_gap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances[inst_set][\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m      9\u001b[0m     purchase,benchmark \u001b[38;5;241m=\u001b[39m inst_gen\u001b[38;5;241m.\u001b[39mupload_CVRP_instance(inst_set,instance)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'routing_instances' has no attribute 'routing_instances'"
     ]
    }
   ],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.routing_instances.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.routing_instances.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.routing_instances.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: \n",
    "                string = verb.routing_instances.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap:', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Uchoa set Instances  *****************************\n",
      "----------------|\tNN \t|\t     RCL \t \t|\n",
      "Sizes\t  Num \t| t(s) \t   gap \t| t(s)\t  mean\t median \t   min\t   max\t|\n",
      "-----------------------------------------------------------------\n",
      "100-199\t    21\t|\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     NN_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (((NN_performance[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list))\n\u001b[1;32m     46\u001b[0m     NN_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m NN_performance[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_set)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUchoa/RCL/Random/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     50\u001b[0m     RCL_performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     51\u001b[0m     RCL_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((RCL_performance[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list)\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'"
     ]
    }
   ],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intra-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
