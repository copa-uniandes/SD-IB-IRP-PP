{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################     Modules     #######################################\n",
    "import sys\n",
    "from time import process_time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../.')\n",
    "from verbose_module import routing_instances as verb\n",
    "sys.path.append('../../../.')\n",
    "import pIRPgym\n",
    "\n",
    "\n",
    "computer_name = input(\"Running experiment on mac? [Y/n]\")\n",
    "if computer_name == '': \n",
    "    path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/pIRPgym/'\n",
    "    experiments_path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "else: \n",
    "    path = 'C:/Users/jm.betancourt/Documents/Research/pIRPgym/'\n",
    "    experiments_path = 'G:/Mi unidad/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "\n",
    "\n",
    "instances = dict()\n",
    "instances['Li'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Li') if i[-3:]=='vrp']\n",
    "instances['Golden'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Golden') if i[-3:]=='vrp']\n",
    "instances['Uchoa'] = [i for i in os.listdir(path+'pIRPgym/Instances/CVRP Instances/CVRP/Uchoa') if i[-3:]=='vrp']\n",
    "instances['Li'].sort();instances['Golden'].sort()\n",
    "instances['Uchoa'].sort();instances['Uchoa'] = instances['Uchoa'][1:]+[instances['Uchoa'][0]]\n",
    "\n",
    "Policies = ['NN','RCL']\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dCVRP Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************  Li set Instances  ********************************************************\n",
      "--------|-----------------------|\t  NN \t \t|\t  GA \t \t|\t  \t  \t \tRCL \t \t \t|\n",
      "Inst\t|   M \t  Veh\t Obj\t| t(s)\t #Veh \t gap \t| t(s)\t #Veh \t gap \t| t(s)\t #Veh \t mean \tmedian\t stdev\t min\t max\t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Li 21 \t|  560\t  10 \t16213 \t| 0.03\t  13\t 28.0\t| 0.16\t  14.8\t 46.63\t 35.18 \t27.38\t  24.5\t 130.31\t|\n",
      "Li 22 \t|  600\t  15 \t14499 \t| 0.00\t  22\t 31.72\t| 0.09\t  24.3\t 47.54\t 42.62 \t11.58\t  36.62\t 74.5\t|\n",
      "Li 23 \t|  640\t  10 \t18801 \t| 0.00\t  14\t 41.85\t| 0.13\t  13.8\t 43.66\t 32.81 \t30.65\t  20.93\t 151.15\t|\n",
      "Li 24 \t|  720\t  10 \t21389 \t| 0.06\t  13\t 30.59\t| 0.16\t  14.8\t 49.19\t 35.24 \t34.23\t  26.75\t 168.69\t|\n",
      "Li 25 \t|  760\t  19 \t16666 \t| 0.05\t  28\t 31.56\t| 0.16\t  30.1\t 40.96\t 39.63 \t7.12\t  31.74\t 68.16\t|\n",
      "Li 26 \t|  800\t  10 \t23978 \t| 0.03\t  14\t 27.61\t| 0.20\t  16.1\t 55.42\t 36.09 \t39.46\t  25.56\t 183.53\t|\n",
      "Li 27 \t|  840\t  20 \t17320 \t| 0.05\t  29\t 26.82\t| 0.22\t  32.1\t 44.38\t 37.0 \t18.0\t  32.04\t 114.97\t|\n",
      "Li 28 \t|  880\t  10 \t26566 \t| 0.08\t  14\t 29.18\t| 0.26\t  15.0\t 42.83\t 32.27 \t37.65\t  20.99\t 203.73\t|\n",
      "Li 29 \t|  960\t  10 \t29154 \t| 0.11\t  14\t 32.12\t| 0.31\t  15.6\t 49.14\t 33.56 \t43.6\t  22.12\t 219.43\t|\n",
      "Li 30 \t|  1040\t  10 \t31743 \t| 0.06\t  14\t 30.07\t|\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/RCL/Li_30.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m policy\u001b[38;5;241m==\u001b[39mPolicies[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]: end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(f'{inst_set}/{policy}/{instance[:-4]}.pkl')\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minst_set\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpolicy\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Use pickle.dump to serialize and save the dictionary to the file\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m policy\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/RCL/Li_30.pkl'"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "for inst_set in ['Li','Golden']:\n",
    "    if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "    \n",
    "    for instance in instances[inst_set]:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "        if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "        \n",
    "        for policy in Policies:\n",
    "            end=False\n",
    "            if policy==Policies[-1]: end=True\n",
    "            # print(f'{inst_set}/{policy}/{instance[:-4]}.pkl')\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "            \n",
    "            if policy=='NN':\n",
    "                if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                 performance[3],True,benchmark,end=end)\n",
    "            elif policy=='RCL':\n",
    "                if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                 performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/GA/Li_21_250_0.05_0.25.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m purchase,benchmark \u001b[38;5;241m=\u001b[39m inst_gen\u001b[38;5;241m.\u001b[39mupload_CVRP_instance(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLi\u001b[39m\u001b[38;5;124m'\u001b[39m,instance)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (p,e,m) \u001b[38;5;129;01min\u001b[39;00m combinations:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLi/GA/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43me\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mm\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# Use pickle.dump to serialize and save the dictionary to the file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     20\u001b[0m         per[(p,e,m)]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m((performance[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/GA/Li_21_250_0.05_0.25.pkl'"
     ]
    }
   ],
   "source": [
    "POPULATION_SIZES = [250,750,1000,2500]\n",
    "ELITE_PROPORTIONS = [0.05,0.15,0.3]\n",
    "MUTATION_RATES = [0.25,0.5,0.75]\n",
    "\n",
    "combinations = [(p,e,m) for p in POPULATION_SIZES for e in ELITE_PROPORTIONS for m in MUTATION_RATES]\n",
    "per = {com:list() for com in combinations}\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "\n",
    "for instance in instances['Li'][0:8]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance('Li',instance)\n",
    "\n",
    "    # for (p,e,m) in combinations:\n",
    "    with open(experiments_path+f'Li/GA/{instance[:-4]}_{p}_{e}_{m}.pkl', 'rb') as file:\n",
    "        # Use pickle.dump to serialize and save the dictionary to the file\n",
    "        performance = pickle.load(file)\n",
    "\n",
    "    per[(p,e,m)].append(round((performance[1]-benchmark[0])/benchmark[0],2))\n",
    "        # print(f'{p}_{e}_{m} \\t',round((performance[1]-benchmark[0])/benchmark[0],2))\n",
    "        # print(f'{p}_{e}_{m} \\t',performance[1])\n",
    "\n",
    "per = {com:sum(per[com])/len(per[com]) for com in combinations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 0.05, 0.25) \t 0.7749999999999999\n",
      "(250, 0.05, 0.5) \t 0.78125\n",
      "(250, 0.05, 0.75) \t 0.7737499999999999\n",
      "(250, 0.15, 0.25) \t 0.77\n",
      "(250, 0.15, 0.5) \t 0.78\n",
      "(250, 0.15, 0.75) \t 0.7775000000000001\n",
      "(250, 0.3, 0.25) \t 0.76875\n",
      "(250, 0.3, 0.5) \t 0.7875000000000001\n",
      "(250, 0.3, 0.75) \t 0.7712500000000002\n",
      "(750, 0.05, 0.25) \t 0.7675000000000001\n",
      "(750, 0.05, 0.5) \t 0.76375\n",
      "(750, 0.05, 0.75) \t 0.7575\n",
      "(750, 0.15, 0.25) \t 0.7662499999999999\n",
      "(750, 0.15, 0.5) \t 0.7562500000000001\n",
      "(750, 0.15, 0.75) \t 0.77\n",
      "(750, 0.3, 0.25) \t 0.7575\n",
      "(750, 0.3, 0.5) \t 0.7725000000000001\n",
      "(750, 0.3, 0.75) \t 0.7675000000000001\n",
      "(1000, 0.05, 0.25) \t 0.76625\n",
      "(1000, 0.05, 0.5) \t 0.74625\n",
      "(1000, 0.05, 0.75) \t 0.7425\n",
      "(1000, 0.15, 0.25) \t 0.73875\n",
      "(1000, 0.15, 0.5) \t 0.7525\n",
      "(1000, 0.15, 0.75) \t 0.925\n",
      "(1000, 0.3, 0.25) \t 0.755\n",
      "(1000, 0.3, 0.5) \t 0.7675000000000001\n",
      "(1000, 0.3, 0.75) \t 0.76875\n",
      "(2500, 0.05, 0.25) \t 0.75125\n",
      "(2500, 0.05, 0.5) \t 0.7374999999999999\n",
      "(2500, 0.05, 0.75) \t 0.7474999999999999\n",
      "(2500, 0.15, 0.25) \t 0.7575000000000001\n",
      "(2500, 0.15, 0.5) \t 0.74625\n",
      "(2500, 0.15, 0.75) \t 0.74375\n",
      "(2500, 0.3, 0.25) \t 0.7375\n",
      "(2500, 0.3, 0.5) \t 0.7525000000000001\n",
      "(2500, 0.3, 0.75) \t 0.7549999999999999\n"
     ]
    }
   ],
   "source": [
    "for com in combinations:\n",
    "    print(com, '\\t', per[com])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVRP Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exo-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'routing_instances' has no attribute 'routing_instances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m inst_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUchoa\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m RCL_averge_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: verb\u001b[38;5;241m.\u001b[39mrouting_instances\u001b[38;5;241m.\u001b[39mprint_head(Policies,inst_set,show_gap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances[inst_set][\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m      9\u001b[0m     purchase,benchmark \u001b[38;5;241m=\u001b[39m inst_gen\u001b[38;5;241m.\u001b[39mupload_CVRP_instance(inst_set,instance)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'routing_instances' has no attribute 'routing_instances'"
     ]
    }
   ],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.routing_instances.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.routing_instances.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.routing_instances.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: \n",
    "                string = verb.routing_instances.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap:', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Uchoa set Instances  *****************************\n",
      "----------------|\tNN \t|\t     RCL \t \t|\n",
      "Sizes\t  Num \t| t(s) \t   gap \t| t(s)\t  mean\t median \t   min\t   max\t|\n",
      "-----------------------------------------------------------------\n",
      "100-199\t    21\t|\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     NN_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (((NN_performance[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list))\n\u001b[1;32m     46\u001b[0m     NN_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m NN_performance[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_set)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUchoa/RCL/Random/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     50\u001b[0m     RCL_performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     51\u001b[0m     RCL_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((RCL_performance[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list)\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'"
     ]
    }
   ],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intra-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
