{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################     Modules     #######################################\n",
    "import sys\n",
    "from time import process_time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.path.append('../.')\n",
    "from verbose_module import routing_instances as verb\n",
    "sys.path.append('../../../.')\n",
    "import pIRPgym\n",
    "\n",
    "\n",
    "computer_name = input(\"Running experiment on mac? [Y/n]\")\n",
    "if computer_name == '': \n",
    "    path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/pIRPgym/'\n",
    "    experiments_path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "else: \n",
    "    path = 'C:/Users/jm.betancourt/Documents/Research/pIRPgym/'\n",
    "    experiments_path = 'G:/Mi unidad/Research/Supply Chain Analytics/Experiments/Classic Instances/'\n",
    "\n",
    "\n",
    "instances = dict()\n",
    "instances['Li'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Li') if i[-3:]=='vrp']\n",
    "instances['Golden'] = [i for i in os.listdir(path+'/pIRPgym/Instances/CVRP Instances/dCVRP/Golden') if i[-3:]=='vrp']\n",
    "instances['Uchoa'] = [i for i in os.listdir(path+'pIRPgym/Instances/CVRP Instances/CVRP/Uchoa') if i[-3:]=='vrp']\n",
    "instances['Li'].sort();instances['Golden'].sort()\n",
    "instances['Uchoa'].sort();instances['Uchoa'] = instances['Uchoa'][1:]+[instances['Uchoa'][0]]\n",
    "\n",
    "Policies = ['NN','RCL','GA']\n",
    "\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dCVRP Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************  Golden set Instances  ********************************************************\n",
      "--------|-----------------------|\t  NN \t \t|\t  \t  \t \tRCL \t \t \t|\t  GA \t \t|\n",
      "Inst\t|   M \t  Veh\t Obj\t| t(s)\t #Veh \t gap \t| t(s)\t #Veh \t mean \tmedian\t stdev\t min\t max\t| t(s)\t #Veh \t gap \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Go 1 \t|  240\t  9 \t5623 \t| 0.00\t  14\t 32.18\t| 0.03\t  13.9\t 35.84\t 33.82 \t8.86\t  27.02\t 68.95\t| 34.9\t  13\t 32.34\t|\n",
      "Go 2 \t|  320\t  10 \t8405 \t| 0.02\t  15\t 33.93\t| 0.03\t  15.4\t 41.52\t 36.38 \t14.85\t  28.49\t 87.19\t| 126.0\t  14\t 42.7\t|\n",
      "Go 3 \t|  400\t  9 \t10998 \t| 0.00\t  15\t 39.93\t| 0.05\t  15.1\t 47.81\t 36.8 \t19.74\t  30.95\t 102.04\t| 168.0\t  15\t 52.53\t|\n",
      "Go 4 \t|  480\t  10 \t13589 \t| 0.02\t  13\t 31.83\t| 0.07\t  13.3\t 33.77\t 30.16 \t11.18\t  23.46\t 76.41\t| 201.0\t  14\t 56.45\t|\n",
      "Go 5 \t|  200\t  5 \t6461 \t| 0.00\t  6\t 49.44\t| 0.02\t  6.0\t 38.1\t 34.54 \t12.36\t  19.36\t 89.29\t| 38.9\t  5\t 27.24\t|\n",
      "Go 6 \t|  280\t  7 \t8400 \t| 0.00\t  8\t 22.97\t| 0.02\t  8.8\t 36.53\t 30.53 \t20.45\t  19.46\t 102.42\t| 8.21\t  8\t 36.48\t|\n",
      "Go 7 \t|  360\t  8 \t10103 \t| 0.00\t  11\t 23.5\t| 0.03\t  12.3\t 36.55\t 34.12 \t9.18\t  24.52\t 70.28\t| 208.0\t  12\t 50.21\t|\n",
      "Go 8 \t|  440\t  10 \t11635 \t| 0.00\t  15\t 34.25\t| 0.05\t  16.5\t 51.46\t 40.47 \t22.54\t  30.52\t 103.99\t| 154.0\t  16\t 54.0\t|\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "for inst_set in ['Li','Golden']:\n",
    "    if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "    \n",
    "    for instance in instances[inst_set]:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "        if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "        \n",
    "        for policy in Policies:\n",
    "            end=False\n",
    "            if policy==Policies[-1]: end=True\n",
    "            # print(f'{inst_set}/{policy}/{instance[:-4]}.pkl')\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "            \n",
    "            if policy in ['NN','GA']:\n",
    "                if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                 performance[3],True,benchmark,end=end)\n",
    "            elif policy=='RCL':\n",
    "                if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                 performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/GA/Li_21_250_0.05_0.25.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m purchase,benchmark \u001b[38;5;241m=\u001b[39m inst_gen\u001b[38;5;241m.\u001b[39mupload_CVRP_instance(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLi\u001b[39m\u001b[38;5;124m'\u001b[39m,instance)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (p,e,m) \u001b[38;5;129;01min\u001b[39;00m combinations:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLi/GA/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43me\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mm\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# Use pickle.dump to serialize and save the dictionary to the file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     20\u001b[0m         per[(p,e,m)]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mround\u001b[39m((performance[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Li/GA/Li_21_250_0.05_0.25.pkl'"
     ]
    }
   ],
   "source": [
    "POPULATION_SIZES = [250,750,1000,2500]\n",
    "ELITE_PROPORTIONS = [0.05,0.15,0.3]\n",
    "MUTATION_RATES = [0.25,0.5,0.75]\n",
    "\n",
    "combinations = [(p,e,m) for p in POPULATION_SIZES for e in ELITE_PROPORTIONS for m in MUTATION_RATES]\n",
    "per = {com:list() for com in combinations}\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "\n",
    "\n",
    "for instance in instances['Li'][0:8]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance('Li',instance)\n",
    "\n",
    "    # for (p,e,m) in combinations:\n",
    "    with open(experiments_path+f'Li/GA/{instance[:-4]}_{p}_{e}_{m}.pkl', 'rb') as file:\n",
    "        # Use pickle.dump to serialize and save the dictionary to the file\n",
    "        performance = pickle.load(file)\n",
    "\n",
    "    per[(p,e,m)].append(round((performance[1]-benchmark[0])/benchmark[0],2))\n",
    "        # print(f'{p}_{e}_{m} \\t',round((performance[1]-benchmark[0])/benchmark[0],2))\n",
    "        # print(f'{p}_{e}_{m} \\t',performance[1])\n",
    "\n",
    "per = {com:sum(per[com])/len(per[com]) for com in combinations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 0.05, 0.25) \t 0.7749999999999999\n",
      "(250, 0.05, 0.5) \t 0.78125\n",
      "(250, 0.05, 0.75) \t 0.7737499999999999\n",
      "(250, 0.15, 0.25) \t 0.77\n",
      "(250, 0.15, 0.5) \t 0.78\n",
      "(250, 0.15, 0.75) \t 0.7775000000000001\n",
      "(250, 0.3, 0.25) \t 0.76875\n",
      "(250, 0.3, 0.5) \t 0.7875000000000001\n",
      "(250, 0.3, 0.75) \t 0.7712500000000002\n",
      "(750, 0.05, 0.25) \t 0.7675000000000001\n",
      "(750, 0.05, 0.5) \t 0.76375\n",
      "(750, 0.05, 0.75) \t 0.7575\n",
      "(750, 0.15, 0.25) \t 0.7662499999999999\n",
      "(750, 0.15, 0.5) \t 0.7562500000000001\n",
      "(750, 0.15, 0.75) \t 0.77\n",
      "(750, 0.3, 0.25) \t 0.7575\n",
      "(750, 0.3, 0.5) \t 0.7725000000000001\n",
      "(750, 0.3, 0.75) \t 0.7675000000000001\n",
      "(1000, 0.05, 0.25) \t 0.76625\n",
      "(1000, 0.05, 0.5) \t 0.74625\n",
      "(1000, 0.05, 0.75) \t 0.7425\n",
      "(1000, 0.15, 0.25) \t 0.73875\n",
      "(1000, 0.15, 0.5) \t 0.7525\n",
      "(1000, 0.15, 0.75) \t 0.925\n",
      "(1000, 0.3, 0.25) \t 0.755\n",
      "(1000, 0.3, 0.5) \t 0.7675000000000001\n",
      "(1000, 0.3, 0.75) \t 0.76875\n",
      "(2500, 0.05, 0.25) \t 0.75125\n",
      "(2500, 0.05, 0.5) \t 0.7374999999999999\n",
      "(2500, 0.05, 0.75) \t 0.7474999999999999\n",
      "(2500, 0.15, 0.25) \t 0.7575000000000001\n",
      "(2500, 0.15, 0.5) \t 0.74625\n",
      "(2500, 0.15, 0.75) \t 0.74375\n",
      "(2500, 0.3, 0.25) \t 0.7375\n",
      "(2500, 0.3, 0.5) \t 0.7525000000000001\n",
      "(2500, 0.3, 0.75) \t 0.7549999999999999\n"
     ]
    }
   ],
   "source": [
    "for com in combinations:\n",
    "    print(com, '\\t', per[com])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVRP Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exo-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'routing_instances' has no attribute 'routing_instances'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m inst_set\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUchoa\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m RCL_averge_gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: verb\u001b[38;5;241m.\u001b[39mrouting_instances\u001b[38;5;241m.\u001b[39mprint_head(Policies,inst_set,show_gap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m instances[inst_set][\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m      9\u001b[0m     purchase,benchmark \u001b[38;5;241m=\u001b[39m inst_gen\u001b[38;5;241m.\u001b[39mupload_CVRP_instance(inst_set,instance)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'routing_instances' has no attribute 'routing_instances'"
     ]
    }
   ],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.routing_instances.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.routing_instances.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.routing_instances.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: \n",
    "                string = verb.routing_instances.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap:', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Uchoa set Instances  *****************************\n",
      "----------------|\tNN \t|\t     RCL \t \t|\n",
      "Sizes\t  Num \t| t(s) \t   gap \t| t(s)\t  mean\t median \t   min\t   max\t|\n",
      "-----------------------------------------------------------------\n",
      "100-199\t    21\t|\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     NN_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (((NN_performance[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list))\n\u001b[1;32m     46\u001b[0m     NN_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m NN_performance[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_set)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexperiments_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUchoa/RCL/Random/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minstance\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     50\u001b[0m     RCL_performance \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     51\u001b[0m     RCL_gap \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((RCL_performance[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mbenchmark[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inst_list)\n",
      "File \u001b[0;32m~/micromamba/envs/SCAEnv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/Classic Instances/Uchoa/RCL/Random/X-n101-k25.pkl'"
     ]
    }
   ],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Random/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intra-alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for instance in instances[inst_set][1:]:\n",
    "    purchase,benchmark = inst_gen.upload_CVRP_instance(inst_set,instance)\n",
    "    if verbose: string = verb.print_inst(inst_set,instance,inst_gen.M,benchmark[1],benchmark[0])\n",
    "    \n",
    "    for policy in Policies:\n",
    "        end=False\n",
    "        if policy==Policies[-1]: end=True\n",
    "\n",
    "        if policy == 'RCL':\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        else:\n",
    "            with open(experiments_path+f'{inst_set}/{policy}/{instance[:-4]}.pkl', 'rb') as file:\n",
    "                # Use pickle.dump to serialize and save the dictionary to the file\n",
    "                performance = pickle.load(file)\n",
    "        \n",
    "        if policy=='NN':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[1],len(performance[0]),\n",
    "                                                                                performance[3],True,benchmark,end=end)\n",
    "        elif policy=='RCL':\n",
    "            if verbose: string = verb.print_routing_update(string,performance[0],performance[1],\n",
    "                                                                                performance[2],True,benchmark,intervals=performance[3],end=end)\n",
    "            RCL_averge_gap+=((performance[0]-benchmark[0])/benchmark[0])/100\n",
    "\n",
    "print('RCL average gap', round(RCL_averge_gap,4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_range_library(instance_names):\n",
    "    node_range_library = {}\n",
    "\n",
    "    for instance_name in instance_names:\n",
    "        # Extract the number of nodes from the instance name\n",
    "        nodes = int(instance_name.split('-n')[1].split('-')[0])\n",
    "\n",
    "        # Determine the range tuple\n",
    "        node_range = ((nodes // 100) * 100, ((nodes // 100) * 100) + 99)\n",
    "\n",
    "        # Add the instance to the corresponding range in the dictionary\n",
    "        if node_range not in node_range_library:\n",
    "            node_range_library[node_range] = [instance_name]\n",
    "        else:\n",
    "            node_range_library[node_range].append(instance_name)\n",
    "\n",
    "    return node_range_library\n",
    "\n",
    "# Example usage:\n",
    "# Call the function to create the library\n",
    "instance_sizes = create_node_range_library(instances['Uchoa'])\n",
    "\n",
    "# Creating instance generator object\n",
    "inst_gen = pIRPgym.instance_generator(False,False,False,False)\n",
    "inst_set='Uchoa'\n",
    "RCL_averge_gap = 0\n",
    "\n",
    "if verbose: verb.print_comparison_head(Policies,inst_set,show_gap=True)\n",
    "\n",
    "for interval,inst_list in instance_sizes.items():\n",
    "\n",
    "    if verbose: string = verb.print_comparison_inst(interval,len(inst_list))\n",
    "    NN_gap = 0\n",
    "    NN_time = 0\n",
    "    RCL_gap = 0\n",
    "    RCL_time = 0\n",
    "    RCL_min = 0\n",
    "    RCL_max = 0\n",
    "\n",
    "    for instance in inst_list:\n",
    "        purchase,benchmark = inst_gen.upload_CVRP_instance('Uchoa',instance)\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/NN/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            NN_performance = pickle.load(file)\n",
    "            NN_gap += (((NN_performance[1]-benchmark[0])/benchmark[0])/len(inst_list))\n",
    "            NN_time += NN_performance[3]/len(inst_set)\n",
    "\n",
    "\n",
    "        with open(experiments_path+f'Uchoa/RCL/Adaptative/{instance[:-4]}.pkl', 'rb') as file:\n",
    "            RCL_performance = pickle.load(file)\n",
    "            RCL_gap += ((RCL_performance[0]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_time += RCL_performance[2]/len(inst_list)/len(inst_list)\n",
    "            RCL_min += ((RCL_performance[3][1]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "            RCL_max += ((RCL_performance[3][2]-benchmark[0])/benchmark[0])/len(inst_list)\n",
    "    \n",
    "\n",
    "    verb.print_routing_comparison_update(string,NN_gap,NN_time,RCL_gap,RCL_time,RCL_min,RCL_max)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
