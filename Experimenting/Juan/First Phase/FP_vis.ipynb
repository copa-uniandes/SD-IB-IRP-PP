{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-02-11\n"
     ]
    }
   ],
   "source": [
    "######################################     Modules     #######################################\n",
    "# MODULES\n",
    "import sys\n",
    "from time import process_time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "sys.path.append('../.')\n",
    "import verbose_module\n",
    "sys.path.append('../../../.')\n",
    "import pIRPgym\n",
    "\n",
    "path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/pIRPgym/'\n",
    "experiments_path = '/Users/juanbeta/My Drive/Research/Supply Chain Analytics/Experiments/First Phase/'\n",
    "\n",
    "Experiments = [i for i in range(1,6)]\n",
    "Replicas = {i:[j for j in range(1,6)] for i in range(1,5)}\n",
    "Replicas.update({5:[1,2,3]})\n",
    "\n",
    "\n",
    "alphas = [0.1,0.2,0.4,0.6,0.8]\n",
    "time_limits = [1,30,60,300,1800,3600]\n",
    "\n",
    "init_times = {1:0.1,30:1,60:3,300:5,1800:5,3600:10}\n",
    "Sizes = {1:5,2:10,3:15,4:20,5:40,6:60}\n",
    "\n",
    "Policies = ['MIP','NN','RCL']+[f'CG_{time_limit}' for time_limit in time_limits]+\\\n",
    "           [f'CG_{time_limit}_{alpha}' for time_limit in time_limits for alpha in alphas]\n",
    "\n",
    "def find_best_performance(experiment,replica):\n",
    "    Results = list()\n",
    "    start = 0 if experiment <= 2 else 1\n",
    "    \n",
    "    results = dict()\n",
    "    for policy in Policies[start:]:\n",
    "        with open(experiments_path+f'Experiment {experiment}/Replica {replica}/{policy}.pkl','rb') as file:\n",
    "                results[policy] = pickle.load(file)\n",
    "        \n",
    "    for t in range(len(results['NN'])):\n",
    "        min_cost = 1e9 \n",
    "        for policy in Policies[start:]:\n",
    "            loc = 1 if policy!='RCL' else 0\n",
    "            obj = results[policy][t][loc] \n",
    "            if obj < min_cost:\n",
    "                min_cost = obj\n",
    "        Results.append(min_cost)\n",
    "    \n",
    "    return Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization by Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314ac9889c9e422187d0dc4eb942d2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Experiments:', index=(0, 1, 2, 3, 4), options=(1, 2, 3, 4, 5…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_experiment_result(experiments, policies, indicator, runtime)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_experiment_result(experiments,policies,indicator,runtime):\n",
    "    policies = list(policies)\n",
    "    policies+=[f'CG_{runtime}']+[f'CG_{runtime}_{alpha}' for alpha in alphas]\n",
    "    \n",
    "    sizes = {experiment:Sizes[experiment] for experiment in experiments}\n",
    "\n",
    "    E_x_values = [f'Exp{exp} (M/K={size})' for exp,size in sizes.items()]\n",
    "\n",
    "    Experiments_results = {('Instance','M/K'):[Sizes[experiment] for experiment in experiments]}\n",
    "    Experiments_results.update({(policy,item):[] for policy in policies for item in ['eff','gaps']})\n",
    "\n",
    "    for experiment in experiments:\n",
    "\n",
    "        reliability = {policy:[] for policy in policies}\n",
    "        gaps = {policy:[] for policy in policies}\n",
    "\n",
    "        for replica in Replicas[experiment]:\n",
    "            with open(experiments_path+f'Experiment {experiment}/Replica {replica}/instance_information.pkl', 'rb') as file:\n",
    "                inst_info = pickle.load(file)\n",
    "\n",
    "            results = dict()\n",
    "            for policy in policies:\n",
    "                with open(experiments_path+f'Experiment {experiment}/Replica {replica}/{policy}.pkl','rb') as file:\n",
    "                    results[policy] = pickle.load(file)\n",
    "\n",
    "            best_performances = find_best_performance(experiment,replica)\n",
    "            for t in range(inst_info['inst_gen'].T):\n",
    "                best_performance = best_performances[t]\n",
    "                \n",
    "                for policy in policies:\n",
    "                    loc = 1 if policy!='RCL' else 0\n",
    "                    \n",
    "                    if (results[policy][t][loc] - best_performance)/best_performance < 0.01:\n",
    "                        reliability[policy].append(1)\n",
    "                    else:\n",
    "                        reliability[policy].append(0)\n",
    "                        gaps[policy].append((results[policy][t][loc]-best_performance)/best_performance)\n",
    "\n",
    "        # Storing the results\n",
    "        for policy in policies:\n",
    "                Experiments_results[(policy,'eff')].append(round(sum(reliability[policy])/len(reliability[policy]),4))\n",
    "                if len(gaps[policy]) > 0:\n",
    "                    Experiments_results[(policy,'gaps')].append(round(sum(gaps[policy])/len(gaps[policy]),4))\n",
    "                else:\n",
    "                    Experiments_results[(policy,'gaps')].append(0)\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    df = pd.DataFrame(Experiments_results)\n",
    "    df.index = experiments\n",
    "    df = df.style.format(dict.fromkeys(list(df.columns)[1:],\"{:.2%}\"))\n",
    "    display(df)\n",
    "\n",
    "    print('\\n')\n",
    "    E_results = dict()\n",
    "    for policy in policies:\n",
    "        E_results[policy] ={'effectiveness':Experiments_results[str(policy),'eff'],'gap':Experiments_results[str(policy),'gaps']} \n",
    "    \n",
    "    pIRPgym.Visualizations.RoutingV.plot_indicator_evolution(E_results,indicator,x_axis='Experiments',x_values=E_x_values)\n",
    "\n",
    "interact(plot_experiment_result,\n",
    "         experiments = widgets.SelectMultiple(options=Experiments,value=Experiments,rows=5,description='Experiments:'),\n",
    "         policies=widgets.SelectMultiple(options=['MIP','NN','RCL'],value=['NN','RCL'],rows=3,description='Policies:'),\n",
    "         indicator=widgets.Dropdown(options=['effectiveness','gap'],value='effectiveness',description='Indicator:'),\n",
    "         runtime=widgets.Dropdown(options=[1,30,60,300,1800,3600],value=1,description='CG run time:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization by Supplier Number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af676bce1d874e439066b93bc88f8862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Experiments', index=(0, 1, 2, 3, 4), options=(1, 2, 3, 4, 5)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_supplier_num_results(experiments, policies, indicator, display_range, runtime)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_supplier_num_results(experiments,policies,indicator,display_range,runtime):\n",
    "    policies = list(policies)\n",
    "    policies+=[f'CG_{runtime}']+[f'CG_{runtime}_{alpha}' for alpha in alphas]\n",
    "\n",
    "    Suppliers_results = {('Instance','M/K'):[],('Instance','Number'):[]}\n",
    "    Suppliers_results.update({(policy,item):[] for policy in policies for item in ['eff','gaps']})\n",
    "\n",
    "    reliability = {policy:dict() for policy in policies}\n",
    "    gaps = {policy:dict() for policy in policies}\n",
    "\n",
    "    for experiment in experiments:\n",
    "        for replica in Replicas[experiment]:\n",
    "            # Upload results\n",
    "            with open(experiments_path+f'Experiment {experiment}/Replica {replica}/instance_information.pkl', 'rb') as file:\n",
    "                inst_info = pickle.load(file)\n",
    "\n",
    "            results = dict()\n",
    "            for policy in policies: \n",
    "                with open(experiments_path+f'Experiment {experiment}/Replica {replica}/{policy}.pkl', 'rb') as file:\n",
    "                    results[policy] = pickle.load(file)\n",
    "\n",
    "            \n",
    "            best_performances = find_best_performance(experiment,replica)\n",
    "            # For each day determine the best score\n",
    "            for t in range(inst_info['inst_gen'].T):\n",
    "                num_suppliers = len([node for route in results['NN'][t][0] for node in route if node != 0])\n",
    "                if num_suppliers not in reliability['NN'].keys():\n",
    "                    for policy in policies:\n",
    "                        reliability[policy][num_suppliers] = list()\n",
    "                        gaps[policy][num_suppliers] = list()\n",
    "\n",
    "                best_performance = best_performances[t]\n",
    "\n",
    "                for policy in policies: \n",
    "                    pos = 1 if policy != 'RCL' else 0\n",
    "                    if (results[policy][t][pos] - best_performance)/best_performance < 0.01:\n",
    "                        reliability[policy][num_suppliers].append(1)\n",
    "                    else:\n",
    "                        reliability[policy][num_suppliers].append(0)\n",
    "                        gaps[policy][num_suppliers].append((results[policy][t][pos]-best_performance)/best_performance)\n",
    "\n",
    "                        \n",
    "\n",
    "    # Storing the results\n",
    "    supplier_categories = sorted(list(set(reliability[policies[0]].keys())))\n",
    "    Suppliers_results[('Instance','M/K')] = supplier_categories\n",
    "\n",
    "    for sup_num in supplier_categories:\n",
    "        Suppliers_results[('Instance','Number')].append(len(reliability[\"NN\"][sup_num]))\n",
    "\n",
    "\n",
    "        for policy in policies:\n",
    "            Suppliers_results[(str(policy),'eff')].append(round(sum(reliability[policy][sup_num])/len(reliability[policy][sup_num]),4))\n",
    "            if len(gaps[policy][sup_num]) > 0:\n",
    "                Suppliers_results[(str(policy),'gaps')].append(round(sum(gaps[policy][sup_num])/len(gaps[policy][sup_num]),4))\n",
    "            else:\n",
    "                Suppliers_results[(str(policy),'gaps')].append(0)\n",
    "\n",
    "    print('\\n')\n",
    "    df = pd.DataFrame(Suppliers_results)\n",
    "    df.index = supplier_categories\n",
    "    # df.columns = ['M/K','Regular', 'al 0.1','al 0.2','al 0.4','al 0.6']\n",
    "    df = df.style.format(dict.fromkeys(list(df.columns)[2:],\"{:.2%}\"))\n",
    "    # display(df)\n",
    "\n",
    "    results = dict()\n",
    "    for policy in policies:\n",
    "        results[policy] = {'effectiveness':Suppliers_results[policy,'eff']}\n",
    "        results[policy].update({'gaps':Suppliers_results[policy,'gaps']})\n",
    "\n",
    "    display_num_suppliers = list()\n",
    "    display_results = dict()\n",
    "    for policy in policies:\n",
    "        display_results[policy] = {'effectiveness':list()}\n",
    "        display_results[policy].update({'gap':list()})\n",
    "\n",
    "    for i,num in enumerate(supplier_categories):\n",
    "        if num >= display_range[0] and num <= display_range[1]:\n",
    "            display_num_suppliers.append(num)\n",
    "            for policy in policies:\n",
    "                display_results[policy]['effectiveness'].append(results[policy]['effectiveness'][i])\n",
    "                display_results[policy]['gap'].append(results[policy]['gaps'][i])\n",
    "\n",
    "    print('\\n')\n",
    "    pIRPgym.Visualizations.RoutingV.plot_indicator_evolution(display_results,indicator,x_axis='# Suppliers',\n",
    "                                                             x_values=display_num_suppliers)\n",
    "\n",
    "interact(plot_supplier_num_results,\n",
    "         experiments = widgets.SelectMultiple(options=Experiments,value=Experiments,rows=5,description='Experiments'),\n",
    "         policies=widgets.SelectMultiple(options=['MIP','NN','RCL'],value=['NN','RCL'],rows=3,description='Policies:'),\n",
    "         indicator=widgets.Dropdown(options=['effectiveness','gap'],value='effectiveness',description='Indicator:'),\n",
    "         display_range=widgets.IntRangeSlider(  value=[1,40],min=1,max=40,step=1,\n",
    "                                                description='# Suppliers:',continuous_update=False,\n",
    "                                                orientation='horizontal',readout=True,\n",
    "                                                readout_format='d'),\n",
    "         runtime=widgets.Dropdown(options=[1,30,60,300,1800,3600],value=1,description='CG run time:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization by Replica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7605883a76da47f68059505aa3cdb60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Experiment:', options=(1, 2, 3, 4, 5), value=1), Dropdown(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_replica_results(experiment, replica, runtime)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_replica_results(experiment,replica,runtime):\n",
    "    if experiment <= 2:\n",
    "        policies = ['MIP','NN','RCL',f'CG_{runtime}']+[f'CG_{runtime}_{alpha}' for alpha in alphas]\n",
    "    else:\n",
    "        policies = ['NN','RCL',f'CG_{runtime}']+[f'CG_{runtime}_{alpha}' for alpha in alphas]\n",
    "\n",
    "    Replica_results = {('Instance','Step'):[],('Instance','# Suppliers'):[]}\n",
    "    # Replica_results.update({(policy,'gap'):[] for policy in policies})\n",
    "    # Replica_results.update({(policy,item):[] for policy in policies[-6:] for item in ['RCL_cols','CG_cols']})\n",
    "\n",
    "    gaps = {policy:[] for policy in policies}\n",
    "    RCL_cols = {policy:[] for policy in policies[-6:]}\n",
    "    CG_cols = {policy:[] for policy in policies[-6:]}\n",
    "\n",
    "    # Upload results\n",
    "    with open(experiments_path+f'Experiment {experiment}/Replica {replica}/instance_information.pkl', 'rb') as file:\n",
    "            inst_info = pickle.load(file)\n",
    "\n",
    "    R_results = dict()\n",
    "    for policy in policies:\n",
    "            with open(experiments_path+f'Experiment {experiment}/Replica {replica}/{policy}.pkl', 'rb') as file:\n",
    "                    R_results[policy] = pickle.load(file)\n",
    "\n",
    "    best_performances = find_best_performance(experiment,replica)\n",
    "    for t in range(inst_info['inst_gen'].T):\n",
    "        Replica_results[('Instance','Step')].append(t+1)\n",
    "        Replica_results[('Instance','# Suppliers')].append(len(inst_info[\"Requirements\"][t]))\n",
    "\n",
    "        best_performance = best_performances[t]\n",
    "\n",
    "        for policy in policies:\n",
    "            loc = 1 if policy!='RCL' else 0\n",
    "            \n",
    "            if (R_results[policy][t][loc] - best_performance)/best_performance < 0.01:\n",
    "                gaps[policy].append(0)\n",
    "            else:\n",
    "                gaps[policy].append((R_results[policy][t][loc]-best_performance)/best_performance)\n",
    "            \n",
    "            if policy[:3]=='CG_':\n",
    "                RCL_cols[policy].append(R_results[policy][t][4][0])\n",
    "                CG_cols[policy].append(R_results[policy][t][4][1])\n",
    "\n",
    "    R_x_values = [f'{t} ({len(inst_info[\"Requirements\"][t])})' for t in range(inst_info['inst_gen'].T)]\n",
    "\n",
    "    RR_results = dict()\n",
    "\n",
    "    for policy in policies:\n",
    "        Replica_results[(policy,'gap')] = gaps[policy]\n",
    "        RR_results[policy] = {'gap':Replica_results[policy,'gap']} \n",
    "        if policy[:3]=='CG_':\n",
    "            Replica_results[(policy,'RCL_cols')] = RCL_cols[policy]\n",
    "            Replica_results[(policy,'CG_cols')] = CG_cols[policy]\n",
    "       \n",
    "    print('\\n')\n",
    "    df = pd.DataFrame(Replica_results)\n",
    "\n",
    "    if experiment <= 2:\n",
    "        df = df.style.format(dict.fromkeys([list(df.columns)[j] for j in [2,3,4,5,8,11,14,17,20]],\"{:.2%}\"))\n",
    "    else:\n",
    "         df = df.style.format(dict.fromkeys([list(df.columns)[j] for j in [2,3,4,7,10,13,16,19]],\"{:.2%}\"))\n",
    "    display(df)\n",
    "    print('\\n')\n",
    "    pIRPgym.Visualizations.RoutingV.plot_indicator_evolution(RR_results,'gap',x_axis='Steps',x_values=R_x_values)\n",
    "\n",
    "\n",
    "interact(plot_replica_results,\n",
    "         experiment=widgets.Dropdown(options=[i for i in range(1,6)],value=1,description='Experiment:'),\n",
    "         replica=widgets.Dropdown(options=[i for i in range(1,6)],value=1,description='Replica:'),\n",
    "         runtime=widgets.Dropdown(options=[1,30,60,300,1800,3600],value=1,description='CG run time:'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
