{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SD_IB_IRP_PPenv import steroid_IRP\n",
    "from Policies import policies\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "This Notebook has a complete Policy Evaluation function for the Stochastic-Dynamic Inventory-Routing-Problem with Perishable Products. First, the main parameters of the problem and the environment must be set. All the main customizable parameters are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################   Environment's parameters   #################################\n",
    "# SD-IB-IRP-PP model's parameters\n",
    "horizon_type = 'episodic'\n",
    "backorders = False\n",
    "stochastic_parameters = False\n",
    "\n",
    "# Feature's parameters\n",
    "look_ahead = ['*']\n",
    "historical_data = ['*']\n",
    "\n",
    "# Action's parameters\n",
    "validate_action = False\n",
    "warnings = True\n",
    "\n",
    "# Other parameters\n",
    "rd_seed = 0\n",
    "num_episodes = 1000\n",
    "env_config = {  'M': 4, \n",
    "                'K': 4, \n",
    "                'T': 5, \n",
    "                'F': 10,\n",
    "                \n",
    "                'min_sprice': 1,\n",
    "                'max_sprice': 500, \n",
    "                'min_hprice': 1,\n",
    "                'max_hprice': 500,\n",
    "\n",
    "                'back_o_cost':1000,\n",
    "                \n",
    "                'S': 5, \n",
    "                'LA_horizon': 4, \n",
    "                'lambda1': 0.5\n",
    "            }\n",
    "#################################   Environment's parameters   #################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the policy evaluation is defined. This function only takes one parameter, the number of episodes that will be runned of the environment. All the policies to be evaluated must be in the 'Policies.py' file. Any policy used must be able to receive the state, the additional information in _ and the environment as a parameters. Also, the policy function must return an action in the format defined in the Toying.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "def Policy_evaluation(num_episodes = 1000):\n",
    "    \n",
    "    rewards = {}\n",
    "    states = {}\n",
    "    real_actions = {}\n",
    "    backorders = {}\n",
    "    la_decisions = {}\n",
    "    tws = {}\n",
    "    env = steroid_IRP(  horizon_type = horizon_type, look_ahead = look_ahead, historical_data = historical_data,\n",
    "                        backorders = backorders, stochastic_parameters = stochastic_parameters, rd_seed = rd_seed,\n",
    "                        env_config = env_config)\n",
    "\n",
    "    policy = policies()\n",
    "\n",
    "    for episode in range(2):\n",
    "\n",
    "        state, _ = env.reset(return_state = True)\n",
    "        print(env.d)\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            states[episode,env.t] = state\n",
    "            action, la_dec = policy.det_rolling_horizon(state, _, env)\n",
    "            print(state)\n",
    "            print(action)\n",
    "            state, reward, done, real_action, _,  = env.step(action, validate_action = validate_action, warnings = warnings)\n",
    "\n",
    "            real_actions[episode,env.t] = real_action\n",
    "            backorders[episode,env.t] = _[\"bo\"]\n",
    "            rewards[episode,env.t] = reward\n",
    "            la_decisions[episode,env.t] = la_dec\n",
    "            tws[episode,env.t] = _[\"sample_path_window_size\"]\n",
    "            \n",
    "    iterables = (env.Suppliers,env.Products,env.Samples,env.M_kt,env.O_k)\n",
    "    costs = (env.c, env.h_t, env.p_t)\n",
    "\n",
    "    return rewards, states, real_actions, backorders, la_decisions, tws, iterables, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, states, real_actions, backorders, la_decisions, tws, iterables = Policy_evaluation(num_episodes = num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_by_day(episode, day, states, real_actions, backorders, la_decisions, tws, iterables, costs):\n",
    "    \n",
    "    M, K, S, M_kt, O_k = iterables\n",
    "\n",
    "    ''' Realized, Historical Decisions '''\n",
    "    hist_T = range(0,day+1)\n",
    "    # Initial Inventory level for product k, aged o\n",
    "    ii_0 = {t:states[episode,t] for t in hist_T}\n",
    "    # Routing Decisions\n",
    "    rout = {t:real_actions[episode,t][0] for t in hist_T}\n",
    "    # Purchasing decisions\n",
    "    purch = {t:real_actions[episode,t][1] for t in hist_T}\n",
    "    # Backorders\n",
    "    back = {t:backorders[episode,t] for t in hist_T}\n",
    "\n",
    "    ''' Look-ahead Decisions '''\n",
    "    la_T = range(day,day+tws[episode,day])\n",
    "    # Initial Inventory level for product k, aged o in sample path s\n",
    "    ii_0_la = {(t):la_decisions[episode,day][0][t-day] for t in la_T}\n",
    "    # Purchase Decisions\n",
    "    purch_la = {(t):la_decisions[episode,day][1][t-day] for t in la_T}\n",
    "    # Backorders\n",
    "    back_la = {(t):la_decisions[episode,day][2][t-day] for t in la_T}\n",
    "\n",
    "    ''' First Chart: Quantities '''\n",
    "\n",
    "    spec = {\"height_ratios\":[1, 1, 1, 1],\"hspace\":0.25,\"bottom\":0.1,\"top\":0.9}\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(nrows=4,ncols=1,figsize=(13,20),gridspec_kw=spec)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92027e2c1da3bcebf34b84774ed38599ef17aa35363e249514df9920c133b09b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
