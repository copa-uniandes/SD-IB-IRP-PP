{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SD_IB_IRP_PPenv import steroid_IRP\n",
    "from Policies import policies\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "This Notebook has a complete Policy Evaluation function for the Stochastic-Dynamic Inventory-Routing-Problem with Perishable Products. First, the main parameters of the problem and the environment must be set. All the main customizable parameters are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################   Environment's parameters   #################################\n",
    "# Random seed\n",
    "rd_seed = 0\n",
    "\n",
    "# SD-IB-IRP-PP model's parameters\n",
    "backorderss = 'backorders'\n",
    "stochastic_parameters = ['q','d']\n",
    "\n",
    "# Feature's parameters\n",
    "look_ahead = ['q','d']\n",
    "historical_data = ['*']\n",
    "\n",
    "# Action's parameters\n",
    "validate_action = False\n",
    "warnings = False\n",
    "\n",
    "# Other parameters\n",
    "num_episodes = 1\n",
    "env_config = { 'M': 10, 'K': 10, 'T': 20,  'F': 4, \n",
    "               'S': 4,  'LA_horizon': 3, 'back_o_cost':700}\n",
    "\n",
    "q_params = {'distribution': 'c_uniform', 'min': 6, 'max': 20}\n",
    "d_params = {'distribution': 'log-normal', 'mean': 2, 'stdev': 0.5}\n",
    "\n",
    "p_params = {'distribution': 'd_uniform', 'min': 20, 'max': 60}\n",
    "h_params = {'distribution': 'd_uniform', 'min': 20, 'max': 60}\n",
    "\n",
    "#################################   Environment's parameters   #################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the policy evaluation is defined. This function only takes one parameter, the number of episodes that will be runned of the environment. All the policies to be evaluated must be in the 'Policies.py' file. Any policy used must be able to receive the state, the additional information in _ and the environment as a parameters. Also, the policy function must return an action in the format defined in the Toying.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "def Policy_evaluation(num_episodes = 1000):\n",
    "    \n",
    "    rewards = {}\n",
    "    states = {}\n",
    "    real_actions = {}\n",
    "    backorders = {}\n",
    "    la_decisions = {}\n",
    "    realized_dem = {}\n",
    "    q_sample = {}\n",
    "    tws = {}\n",
    "    env = steroid_IRP( look_ahead = look_ahead, \n",
    "                       historical_data = historical_data, \n",
    "                       backorders = backorderss,\n",
    "                       stochastic_parameters = stochastic_parameters, \n",
    "                       env_config = env_config)\n",
    "\n",
    "\n",
    "    policy = policies()\n",
    "\n",
    "    for episode in range(2):\n",
    "\n",
    "        state, _ = env.reset(return_state = True, rd_seed = rd_seed, \n",
    "          q_params = q_params, \n",
    "          p_params = p_params,\n",
    "          d_params = d_params,\n",
    "          h_params = h_params)\n",
    "        #print(env.O_k[0])\n",
    "        #print(state)\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            \n",
    "            states[episode,env.t] = state\n",
    "            action, la_dec = policy.stochastic_rolling_horizon(state, _, env)\n",
    "            #print(state)\n",
    "            #print(action)\n",
    "            q_sample[episode,env.t] = [_[\"sample_paths\"][\"q\"][0,s] for s in env.Samples]\n",
    "            state, reward, done, real_action, _,  = env.step(action, validate_action = validate_action, warnings = warnings)\n",
    "\n",
    "            real_actions[episode,env.t] = real_action\n",
    "            backorders[episode,env.t] = _[\"backorders\"]\n",
    "            rewards[episode,env.t] = reward\n",
    "            la_decisions[episode,env.t] = la_dec\n",
    "            realized_dem[episode,env.t] = env.W_t[\"d\"]\n",
    "            if done:\n",
    "                tws[episode,env.t] = 1\n",
    "            else:\n",
    "                tws[episode,env.t] = _[\"sample_path_window_size\"]\n",
    "            \n",
    "    iterables = (env.Suppliers, env.Products, env.Samples, env.M_kt, env.O_k, env.Horizon)\n",
    "    costs = (env.c, env.h_t, env.p_t, env.back_o_cost)\n",
    "\n",
    "    return rewards, states, real_actions, backorders, la_decisions, realized_dem, q_sample, tws, iterables, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0, (0, 2): 0, (0, 3): 0, (0, 4): 0, (0, 5): 0, (0, 6): 0, (0, 7): 0, (0, 8): 0, (0, 9): 0, (0, 10): 0, (0, 11): 0, (0, 12): 0, (0, 13): 0, (1, 1): 0, (1, 2): 0, (1, 3): 0, (1, 4): 0, (1, 5): 0, (1, 6): 0, (1, 7): 0, (1, 8): 0, (1, 9): 0, (1, 10): 0, (1, 11): 0, (1, 12): 0, (1, 13): 0, (1, 14): 0, (1, 15): 0, (1, 16): 0, (2, 1): 0, (3, 1): 0, (3, 2): 0, (3, 3): 0, (3, 4): 0, (4, 1): 0, (4, 2): 0, (4, 3): 0, (4, 4): 0, (5, 1): 0, (5, 2): 0, (5, 3): 0, (5, 4): 0, (5, 5): 0, (5, 6): 0, (5, 7): 0, (5, 8): 0, (6, 1): 0, (6, 2): 0, (6, 3): 0, (6, 4): 0, (6, 5): 0, (6, 6): 0, (6, 7): 0, (6, 8): 0, (6, 9): 0, (6, 10): 0, (7, 1): 0, (7, 2): 0, (7, 3): 0, (7, 4): 0, (7, 5): 0, (7, 6): 0, (7, 7): 0, (7, 8): 0, (7, 9): 0, (7, 10): 0, (7, 11): 0, (7, 12): 0, (7, 13): 0, (7, 14): 0, (7, 15): 0, (7, 16): 0, (7, 17): 0, (7, 18): 0, (7, 19): 0, (8, 1): 0, (8, 2): 0, (8, 3): 0, (8, 4): 0, (8, 5): 0, (9, 1): 0, (9, 2): 0, (9, 3): 0, (9, 4): 0, (9, 5): 0, (9, 6): 0, (9, 7): 0}\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-02-19\n",
      "{(0, 1): 10.8, (0, 2): 0.0, (0, 3): 0.0, (0, 4): 0.0, (0, 5): 0.0, (0, 6): 0.0, (0, 7): 0.0, (0, 8): 0.0, (0, 9): 0.0, (0, 10): 0.0, (0, 11): 0.0, (0, 12): 0.0, (0, 13): 0.0, (1, 1): 3.7, (1, 2): 0.0, (1, 3): 0.0, (1, 4): 0.0, (1, 5): 0.0, (1, 6): 0.0, (1, 7): 0.0, (1, 8): 0.0, (1, 9): 0.0, (1, 10): 0.0, (1, 11): 0.0, (1, 12): 0.0, (1, 13): 0.0, (1, 14): 0.0, (1, 15): 0.0, (1, 16): 0.0, (2, 1): 8.3, (3, 1): 11.3, (3, 2): 0.0, (3, 3): 0.0, (3, 4): 0.0, (4, 1): 0.0, (4, 2): 0.0, (4, 3): 0.0, (4, 4): 0.0, (5, 1): 0.0, (5, 2): 0, (5, 3): 0, (5, 4): 0, (5, 5): 0, (5, 6): 0, (5, 7): 0, (5, 8): 0, (6, 1): 0.9, (6, 2): 0.0, (6, 3): 0.0, (6, 4): 0.0, (6, 5): 0.0, (6, 6): 0.0, (6, 7): 0.0, (6, 8): 0.0, (6, 9): 0.0, (6, 10): 0.0, (7, 1): 0.0, (7, 2): 0.0, (7, 3): 0.0, (7, 4): 0.0, (7, 5): 0.0, (7, 6): 0.0, (7, 7): 0.0, (7, 8): 0.0, (7, 9): 0.0, (7, 10): 0.0, (7, 11): 0.0, (7, 12): 0.0, (7, 13): 0.0, (7, 14): 0.0, (7, 15): 0.0, (7, 16): 0.0, (7, 17): 0.0, (7, 18): 0.0, (7, 19): 0.0, (8, 1): 5.0, (8, 2): 0, (8, 3): 0, (8, 4): 0, (8, 5): 0, (9, 1): 0.0, (9, 2): 0.0, (9, 3): 0.0, (9, 4): 0.0, (9, 5): 0.0, (9, 6): 0.0, (9, 7): 0.0}\n",
      "{(0, 1): 9.4, (0, 2): -1.0, (0, 3): 0.0, (0, 4): 0.0, (0, 5): 0.0, (0, 6): 0.0, (0, 7): 0.0, (0, 8): 0.0, (0, 9): 0.0, (0, 10): 0.0, (0, 11): 0.0, (0, 12): 0.0, (0, 13): 0.0, (1, 1): 0.0, (1, 2): 0.5, (1, 3): 0.0, (1, 4): 0.0, (1, 5): 0.0, (1, 6): 0.0, (1, 7): 0.0, (1, 8): 0.0, (1, 9): 0.0, (1, 10): 0.0, (1, 11): 0.0, (1, 12): 0.0, (1, 13): 0.0, (1, 14): 0.0, (1, 15): 0.0, (1, 16): 0.0, (2, 1): 9.2, (3, 1): 7.8, (3, 2): 8.9, (3, 3): 0.0, (3, 4): 0.0, (4, 1): 8.2, (4, 2): 0.0, (4, 3): 0.0, (4, 4): 0.0, (5, 1): 0.0, (5, 2): 0.0, (5, 3): 0, (5, 4): 0, (5, 5): 0, (5, 6): 0, (5, 7): 0, (5, 8): 0, (6, 1): 1.5, (6, 2): 0.9, (6, 3): 0.0, (6, 4): 0.0, (6, 5): 0.0, (6, 6): 0.0, (6, 7): 0.0, (6, 8): 0.0, (6, 9): 0.0, (6, 10): 0.0, (7, 1): 7.3, (7, 2): 0.0, (7, 3): 0.0, (7, 4): 0.0, (7, 5): 0.0, (7, 6): 0.0, (7, 7): 0.0, (7, 8): 0.0, (7, 9): 0.0, (7, 10): 0.0, (7, 11): 0.0, (7, 12): 0.0, (7, 13): 0.0, (7, 14): 0.0, (7, 15): 0.0, (7, 16): 0.0, (7, 17): 0.0, (7, 18): 0.0, (7, 19): 0.0, (8, 1): 4.6, (8, 2): 5.0, (8, 3): 0.0, (8, 4): 0.0, (8, 5): 0.0, (9, 1): 0.0, (9, 2): 0.0, (9, 3): 0.0, (9, 4): 0.0, (9, 5): 0.0, (9, 6): 0.0, (9, 7): 0.0}\n",
      "Inventario periodo 0 k = 0, o = 2, s = 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Unable to retrieve attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/juanbeta/My Drive/Investigación/SCA/SD-IB-IRP-PP/Environment/Policy Evaluation.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m rewards, states, real_actions, backorders, la_decisions, realized_dem, q_sample, tws, iterables, costs \u001b[39m=\u001b[39m Policy_evaluation(num_episodes \u001b[39m=\u001b[39;49m num_episodes)\n",
      "\u001b[1;32m/Users/juanbeta/My Drive/Investigación/SCA/SD-IB-IRP-PP/Environment/Policy Evaluation.ipynb Cell 6\u001b[0m in \u001b[0;36mPolicy_evaluation\u001b[0;34m(num_episodes)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     states[episode,env\u001b[39m.\u001b[39mt] \u001b[39m=\u001b[39m state\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     action, la_dec \u001b[39m=\u001b[39m policy\u001b[39m.\u001b[39;49mstochastic_rolling_horizon(state, _, env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m#print(state)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m#print(action)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juanbeta/My%20Drive/Investigaci%C3%B3n/SCA/SD-IB-IRP-PP/Environment/Policy%20Evaluation.ipynb#W5sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     q_sample[episode,env\u001b[39m.\u001b[39mt] \u001b[39m=\u001b[39m [_[\u001b[39m\"\u001b[39m\u001b[39msample_paths\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m,s] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39mSamples]\n",
      "File \u001b[0;32m~/My Drive/Investigación/SCA/SD-IB-IRP-PP/Environment/Policies.py:260\u001b[0m, in \u001b[0;36mpolicies.stochastic_rolling_horizon\u001b[0;34m(self, state, _, env)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m K:\n\u001b[1;32m    259\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m env\u001b[39m.\u001b[39mM_kt[k,env\u001b[39m.\u001b[39mt]:\n\u001b[0;32m--> 260\u001b[0m         purchase[i,k] \u001b[39m=\u001b[39m z[i,k,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mx\n\u001b[1;32m    261\u001b[0m         \u001b[39mif\u001b[39;00m purchase[i,k]\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m    262\u001b[0m             solucionTTP[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][i] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32msrc/gurobipy/var.pxi:125\u001b[0m, in \u001b[0;36mgurobipy.Var.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/var.pxi:153\u001b[0m, in \u001b[0;36mgurobipy.Var.getAttr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/gurobipy/attrutil.pxi:100\u001b[0m, in \u001b[0;36mgurobipy.__getattr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Unable to retrieve attribute 'x'"
     ]
    }
   ],
   "source": [
    "rewards, states, real_actions, backorders, la_decisions, realized_dem, q_sample, tws, iterables, costs = Policy_evaluation(num_episodes = num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_decisions(episode, states, real_actions, backorders, K, T):\n",
    "    # Initial Inventory level for product k, aged o\n",
    "    ii_0 = {t:states[episode,t] for t in T}\n",
    "    # Routing Decisions\n",
    "    rout = {t:real_actions[episode,t][0] for t in T}\n",
    "    # Purchasing decisions\n",
    "    purch = {t:real_actions[episode,t][1] for t in T}\n",
    "    # Backorders\n",
    "    back = {t:{k:backorders[episode,t][k] if k in backorders[episode,t] else 0 for k in K} for t in T}\n",
    "\n",
    "    return ii_0, rout, purch, back\n",
    "\n",
    "def get_lookahead_decisions(episode, day, la_decisions, T):\n",
    "    # Initial Inventory level\n",
    "    ii_0_la = {(t):la_decisions[episode,day][0][t-day] for t in T}\n",
    "    # Purchase Decisions\n",
    "    purch_la = {(t):la_decisions[episode,day][1][t-day] for t in T}\n",
    "    # Backorders\n",
    "    back_la = {(t):la_decisions[episode,day][2][t-day] for t in T}\n",
    "\n",
    "    return ii_0_la, purch_la, back_la\n",
    "\n",
    "def charts_max_axis_values(episode, states, real_actions, backorders, la_decisions, tws, iterables, costs):\n",
    "    \n",
    "    M, K, S, M_kt, O_k, T = iterables\n",
    "\n",
    "    ''' Realized, Historical Decisions '''\n",
    "    ii_0, rout, purch, back = get_historical_decisions(episode,states,real_actions,backorders, K, T)\n",
    "\n",
    "    ''' Lookahead Decisions '''\n",
    "    ii_0_la, purch_la, back_la = {}, {}, {}\n",
    "    for t in T:\n",
    "        ii_0_la[t], purch_la[t], back_la[t] = get_lookahead_decisions(episode, t, la_decisions, range(t,t+tws[episode,t]))\n",
    "\n",
    "    ''' First chart'''\n",
    "    initi = [sum(ii_0[t][k,o] for k in K for o in range(1,O_k[k]+1)) for t in T]\n",
    "    repl = [sum(purch[t][i,k] for i in M for k in K) for t in T]\n",
    "    backo = [sum(back[t][k] for k in K) for t in T]\n",
    "    # Past and today's realized decisions\n",
    "    ub1 = max([initi[t]+repl[t]+backo[t]] for t in T)\n",
    "    initi = {(tau,t,s):sum(ii_0_la[tau][t][s][k,o] for k in K for o in range(1,O_k[k]+1)) for tau in T for t in range(tau,tau+ tws[episode,tau]) for s in S}\n",
    "    repl = {(tau,t,s):sum(purch_la[tau][t][s][i,k] for i in M for k in K) for tau in T for t in range(tau,tau+ tws[episode,tau]) for s in S}\n",
    "    backo = {(tau,t,s):sum(back_la[tau][t][s][k] for k in K) for tau in T for t in range(tau,tau+ tws[episode,tau]) for s in S}\n",
    "    # Future lookahead decisions\n",
    "    ub1 = max(ub1,*[initi[tau,t,s]+repl[tau,t,s] for tau in T for t in range(tau+1,tau+ tws[episode,tau]) for s in S])\n",
    "    # Today lookahead decisions\n",
    "    ub1 = max(ub1,*[initi[tau,tau,s]+repl[tau,tau,s]+backo[tau,tau,s] for tau in T for s in S])\n",
    "    ub1 = (int(ub1/100)+2)*100\n",
    "\n",
    "    ''' Second chart '''\n",
    "    # Max x value\n",
    "    back_li = [sum(back_la[tau][tau][s][k] for k in K) for s in S for tau in T]\n",
    "    ub31 = max(back_li)\n",
    "    ub31 = (int(ub31/10)+1)*10\n",
    "    # Max value for y axis\n",
    "    ub32 = 0\n",
    "    for tau in T:\n",
    "        hist_b = plt.hist([sum(back_la[tau][tau][s][k] for k in K) for s in S])[0]\n",
    "        for i in hist_b:\n",
    "            if i > ub32:\n",
    "                ub32 = i\n",
    "\n",
    "    return [ub1,(ub31,ub32)]\n",
    "\n",
    "\n",
    "def append_routes(rout):\n",
    "    sups = []\n",
    "    for i in rout:\n",
    "        sups += i[1:-1]\n",
    "    sups = list(set(sups))\n",
    "\n",
    "    return sups\n",
    "\n",
    "def quantity_boxplot(ax, suppliers, q_s, K, S, colors, ind):\n",
    "    boxi = ax.boxplot([sum(q_s[s][i,k] for k in K for s in S)/(len(S)) for i in suppliers],positions=[0.75+1.5*ind],widths=[0.3],vert=True,patch_artist=True,flierprops = dict(markerfacecolor=colors[\"box_avail\"][1], markeredgecolor=colors[\"box_avail\"][0]))\n",
    "    return boxi\n",
    "\n",
    "def price_boxplot(ax, suppliers, p, day, K, colors, ind):\n",
    "    price_list = {i:[p[day][i,k] for k in K if p[day][i,k] < 1e3] for i in suppliers}\n",
    "    boxi = ax.boxplot([sum(price_list[i])/len(price_list[i]) for i in suppliers],positions=[1.25+1.5*(ind)],widths=[0.3],vert=True,patch_artist=True,flierprops = dict(markerfacecolor=colors[\"box_prices\"][1], markeredgecolor=colors[\"box_prices\"][0]))\n",
    "    return boxi\n",
    "\n",
    "def visualize_by_day(episode, day, states, real_actions, backorders, la_decisions, realized_dem, q_sample, tws, iterables, costs, conf_level, max_vals, myopic_actions):\n",
    "    \n",
    "    azul = (41/255,122/255,204/255)\n",
    "    verde = (70/255,145/255,57/255)\n",
    "    naranja = (235/255,140/255,68/255)\n",
    "    morado = (99/255,45/255,235/255)\n",
    "    rosado = (199/255,93/255,169/255)\n",
    "\n",
    "    colors = {\"hold\":[naranja,\"palegreen\"],\n",
    "                   \"back\":[azul,\"cyan\"],\n",
    "                   \"purch\":[verde,\"palegreen\"],\n",
    "                   \"rout\":[rosado,\"violet\"],\n",
    "                   \"dem\":[morado,\"mediumpurple\"],\n",
    "                   \"box_avail\":[(91/255,179/255,77/255),(213/255,230/255,123/255)],\n",
    "                   \"box_prices\":[(181/255,21/255,0/255),(223/255,159/255,156/255)]}\n",
    "\n",
    "    M, K, S, M_kt, O_k, T = iterables\n",
    "\n",
    "    ''' Realized, Historical Decisions '''\n",
    "    hist_T = range(day+1)\n",
    "    ii_0, rout, purch, back = get_historical_decisions(episode,states,real_actions,backorders, K, hist_T)\n",
    "\n",
    "    ''' Realized demand '''\n",
    "    d = {t:realized_dem[episode,t] for t in hist_T}\n",
    "\n",
    "    ''' Look-ahead Decisions '''\n",
    "    la_T = range(day,day+tws[episode,day])\n",
    "    ii_0_la, purch_la, back_la = get_lookahead_decisions(episode, day, la_decisions, la_T)\n",
    "\n",
    "    ''' Quantity sample paths '''\n",
    "    q_s = {s:q_sample[day,s] for s in S}\n",
    "\n",
    "    ''' Myopic algorithm decisions '''\n",
    "    rout_myopic = {t:myopic_actions[episode,t][0] for t in T}\n",
    "\n",
    "    ''' Costs '''\n",
    "    c = costs[0]\n",
    "    h = costs[1]\n",
    "    p = costs[2]\n",
    "    g = costs[3]\n",
    "\n",
    "    spec = {\"height_ratios\":[1, 1, 1, 1],\"hspace\":0.25,\"bottom\":0.1,\"top\":0.9}\n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(nrows=4,ncols=1,figsize=(13,20),gridspec_kw=spec)\n",
    "\n",
    "    ''' First Chart: Quantities '''\n",
    "    # Max value for the axis\n",
    "    ub1 = max_vals[0]\n",
    "\n",
    "    # Realized decisions\n",
    "    for t in hist_T:\n",
    "        initi = sum(ii_0[t][k,o] for k in K for o in range(1,O_k[k]+1))\n",
    "        repl = sum(purch[t][i,k] for i in M for k in K)\n",
    "        backo = sum(back[t][k] for k in K)\n",
    "        if t == day:\n",
    "            x_adj = 0.2\n",
    "            wid = 0.4\n",
    "        else:\n",
    "            x_adj = 0\n",
    "            wid = 0.8\n",
    "        ax1.bar(x=t-x_adj, height=initi, color=colors[\"hold\"][0],width=wid)\n",
    "        ax1.bar(x=t-x_adj, height=repl, bottom=initi, color=colors[\"purch\"][0],width=wid)\n",
    "        ax1.bar(x=t-x_adj, height=backo, bottom=initi+repl, color=colors[\"back\"][0], width=wid)\n",
    "\n",
    "    # Look-ahead decisions\n",
    "    for t in la_T:\n",
    "        initi = [sum(ii_0_la[t][s][k,o] for k in K for o in range(1,O_k[k]+1)) for s in S]\n",
    "        repl = [sum(purch_la[t][s][i,k] for i in M for k in K) for s in S]\n",
    "        backo = [sum(back_la[t][s][k] for k in K) for s in S]\n",
    "        if t == day:\n",
    "            tq = [initi[s]+repl[s]+backo[s] for s in S]\n",
    "            cin = st.t.interval(alpha=conf_level, df=len(tq)-1, loc=sum(tq)/len(tq), scale=st.sem(tq)) \n",
    "            ax1.axvline(x=t+0.2,ymin=cin[0]/ub1,ymax=cin[1]/ub1,color=\"black\",marker=\"_\",mew=1.5,ms=8)\n",
    "            bot_back = (sum(initi)+sum(repl))/len(S)\n",
    "            x_adj = 0.2\n",
    "        else:\n",
    "            tq = [initi[s]+repl[s] for s in S]\n",
    "            cin = st.t.interval(alpha=conf_level, df=len(tq)-1, loc=sum(tq)/len(tq), scale=st.sem(tq)) \n",
    "            ax1.axvline(x=t-0.2,ymin=cin[0]/ub1,ymax=cin[1]/ub1,color=\"black\",marker=\"_\",mew=1.5,ms=8)\n",
    "            cin = st.t.interval(alpha=conf_level, df=len(backo)-1, loc=sum(backo)/len(backo), scale=st.sem(backo))\n",
    "            ax1.axvline(x=t+0.2,ymin=cin[0]/ub1,ymax=cin[1]/ub1,color=\"black\",marker=\"_\",mew=1.5,ms=8)\n",
    "            bot_back = 0\n",
    "            x_adj = -0.2\n",
    "        ax1.bar(x=t+x_adj, height=sum(initi)/len(S), color=colors[\"hold\"][0], width=0.4, alpha=0.5)\n",
    "        ax1.bar(x=t+x_adj, height=sum(repl)/len(S), bottom=sum(initi)/len(S), color=colors[\"purch\"][0], width=0.4, alpha = 0.5)\n",
    "        ax1.bar(x=t+0.2, height=sum(backo)/len(S), bottom=bot_back, color=colors[\"back\"][0], width=0.4, alpha=0.5)\n",
    "    \n",
    "    # Historical realized demand\n",
    "    ax1.plot([t for t in hist_T],[sum(d[t][k] for k in K) for t in hist_T],linestyle=\"-\",marker=\"*\",markersize=12,color=\"black\")\n",
    "    \n",
    "    # Chart config\n",
    "    ax1.set_xlim(-0.5,len(T)-0.5)\n",
    "    ax1.set_ylim(0,ub1)\n",
    "    ax1.set_xlabel(\"Time period\")\n",
    "    ax1.set_ylabel(\"Quantity\")\n",
    "    ax1.bar(x=day,height=0,color=colors[\"back\"][0],label=\"Backorders\")\n",
    "    ax1.bar(x=day,height=0,color=colors[\"purch\"][0],label=\"Replenishment\")\n",
    "    ax1.bar(x=day,height=0,color=colors[\"hold\"][0],label=\"Initial Inv. Level\")\n",
    "    ax1.plot(day+len(T),0,color=\"black\",linestyle=\"-\",marker=\"*\",markersize=9,label=\"Demand\")\n",
    "    ax1.legend(loc=\"upper right\",ncol=2)\n",
    "\n",
    "    ''' Second chart: backorders histogram '''\n",
    "    # Max values for axis\n",
    "    ub31, ub32 = max_vals[1]\n",
    "    \n",
    "    # Backorders histogram\n",
    "    ax2.hist([sum(back_la[day][s][k] for k in K) for s in S], color=colors[\"back\"][1], edgecolor=colors[\"back\"][0], alpha = 0.5, density = False, label=\"Backorders\")\n",
    "    \n",
    "    # Chart config\n",
    "    ticks = [i for i in range(0,int(ub31+1),int(ub31/10))]\n",
    "    ax2.set_xticks(ticks=ticks)\n",
    "    ax2.set_xlabel(\"Units\")\n",
    "    ax2.set_xlim(-5,ub31+5)\n",
    "    ax2.set_ylim(0,ub32+1)\n",
    "    ax2.legend(loc=\"upper center\",ncol=2)\n",
    "\n",
    "    ''' Third chart: boxplots '''\n",
    "    \n",
    "    # Availability boxplots\n",
    "    suppliers_visited = {\"all\":M, \"st\":append_routes(rout[day]), \"myo\":append_routes(rout_myopic[day])}\n",
    "\n",
    "    box1 = quantity_boxplot(ax3,suppliers_visited[\"all\"],q_s,K,S,colors,0)\n",
    "    box2 = quantity_boxplot(ax3,suppliers_visited[\"st\"],q_s,K,S,colors,1)\n",
    "    box3 = quantity_boxplot(ax3,suppliers_visited[\"myo\"],q_s,K,S,colors,2)\n",
    "    for boxi in [box1,box2,box3]:\n",
    "        for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "            if item not in ['medians','boxes']:\n",
    "                plt.setp(boxi[item], color = colors[\"box_avail\"][0])\n",
    "            elif item == \"boxes\":\n",
    "                boxi[item][0].set(color = colors[\"box_avail\"][0])\n",
    "                boxi[item][0].set(facecolor = colors[\"box_avail\"][1])\n",
    "            else:\n",
    "                plt.setp(boxi[item], color = colors[\"box_avail\"][0])\n",
    "\n",
    "    # Prices boxplots\n",
    "    ax31 = ax3.twinx()\n",
    "    box5 = price_boxplot(ax31,suppliers_visited[\"all\"],p,day,K,colors,0)\n",
    "    box6 = price_boxplot(ax31,suppliers_visited[\"st\"],p,day,K,colors,1)\n",
    "    box7 = price_boxplot(ax31,suppliers_visited[\"myo\"],p,day,K,colors,2)\n",
    "    for boxi in [box5,box6,box7]:\n",
    "        for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "            if item not in ['medians','boxes']:\n",
    "                plt.setp(boxi[item], color = colors[\"box_prices\"][0])\n",
    "            elif item == \"boxes\":\n",
    "                boxi[item][0].set(color = colors[\"box_prices\"][0])\n",
    "                boxi[item][0].set(facecolor = colors[\"box_prices\"][1])\n",
    "            else:\n",
    "                plt.setp(boxi[item], color = colors[\"box_prices\"][0])\n",
    "\n",
    "    # Chart config\n",
    "    ax31.yaxis.set_major_formatter(\"${x:1.0f}\")\n",
    "    ax31.set_ylabel(\"Price\",rotation=270,labelpad=12)\n",
    "    \n",
    "    ax3.set_xticks([1,2.5,4,5.5])\n",
    "    ax3.set_xticklabels([\"All Suppliers\",f\"Stochastic\",f\"Myopic\",f\"Random\"])\n",
    "    ax3.set_xlabel(\"Subsets of Suppliers\")\n",
    "    ax3.set_ylabel(\"Available Quantity\")\n",
    "    ax3.set_xlim(0.5,6)\n",
    "    ax3.legend(loc=\"upper center\")\n",
    "\n",
    "    ii_real = {t:{(k,o):ii_0[t+1][k,o+1] for k in K for o in range(O_k[k])}}\n",
    "\n",
    "\n",
    "    ''' Fourth chart: Costs '''\n",
    "    # Past decisions\n",
    "    for t in hist_T:\n",
    "        purch = sum(p[t][i,k]*purch[t][i,k] for i in M for k in K)\n",
    "        hold = sum(h[t][k]*ii_real[t][k,o] for k in K for o in range(1,O_k[k]+1))\n",
    "        backo = sum(g*back[t][k] for k in K)\n",
    "        rout = sum(c[rout[t][i][j],rout[t][i][j+1]] for i in range(len(rout[t])) for j in range(len(rout[t][i])-1))\n",
    "        ax4.bar(x=t, height=purch, color=colors[\"purch\"][0])\n",
    "        ax4.bar(x=t, height=hold, bottom=purch, color=colors[\"hold\"][0])\n",
    "        ax4.bar(x=t, height=backo, bottom=purch+hold, color=colors[\"back\"][0])\n",
    "        ax4.bar(x=t, height=rout, bottom=purch+hold+backo, color=colors[\"rout\"][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
